{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescopandolfo/TESI_LM32/blob/main/RF%20-%20variazione_relativa%20-%20eventi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Taz9Rv6bW1FC",
        "outputId": "6f0edda7-df08-4a5a-d724-006444b90772"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y6N3RVtrq6jm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pathDrive = 'drive/MyDrive/UNICT/_TESI/dati/'\n",
        "\n",
        "#df = pd.read_csv('sample_data/dati_interpolati_diff_1d-2d_undsamp_7gg.csv', sep=';')\n",
        "df = pd.read_csv(pathDrive + 'dati_interpolati_diff_1d-2d_8gg - eventi.csv', sep=';')\n",
        "#df = pd.read_csv('tesi/dati_interpolati_diff_1d_undsamp_7gg_2classi.csv', sep=';')\n",
        "#df = pd.read_csv('sample_data/dati_interpolati_diff_3d-3d_undsamp_7gg.csv', sep=';')\n",
        "\n",
        "df['edam_ecne_eplu_diff'] = df['edam_ecne_eplu_diff'].str.replace(',','.').astype(float)#\n",
        "df['edam_ecor_emcn_diff'] = df['edam_ecor_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_emsg_eplu_diff'] = df['edam_emsg_eplu_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_epdn_ecne_diff'] = df['edam_epdn_ecne_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_epdn_emcn_diff'] = df['edam_epdn_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['eint_ecpn_emgl_diff'] = df['eint_ecpn_emgl_diff'].str.replace(',','.').astype(float)#\n",
        "df['eint_esln_emgl_diff'] = df['eint_esln_emgl_diff'].str.replace(',','.').astype(float)\n",
        "df['eint_esln_espc_diff'] = df['eint_esln_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['emeg_ecpn_emgl_diff'] = df['emeg_ecpn_emgl_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_ecor_ecri_diff'] = df['emfn_ecor_ecri_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_ecor_emcn_diff'] = df['emfn_ecor_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_emcn_epdn_diff'] = df['emfn_emcn_epdn_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_ecne_ecpn_diff'] = df['epdn_ecne_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_eint_ecpn_diff'] = df['epdn_eint_ecpn_diff'].str.replace(',','.').astype(float)##\n",
        "df['epdn_eint_espc_diff'] = df['epdn_eint_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_emfn_espc_diff'] = df['epdn_emfn_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_ecne_ecpn_diff'] = df['eplu_ecne_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emeg_ecpn_diff'] = df['eplu_emeg_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emeg_emal_diff'] = df['eplu_emeg_emal_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emsg_emal_diff'] = df['eplu_emsg_emal_diff'].str.replace(',','.').astype(float)\n",
        "\n",
        "_dftarget = df['evento'].astype(int).values\n",
        "\n",
        "format = '%d/%m/%Y'\n",
        "df['date'] = pd.to_datetime(df['day'], format=format)\n",
        "df = df.set_index('date')\n",
        "df = df.drop(columns=['day'])\n",
        "df = df.drop(columns=['evento'])\n",
        "\n",
        "for i in reversed(range(len(df.columns))):\n",
        "  if df.dtypes[df.columns[i]] == 'object':\n",
        "    df = df.drop(df.columns[i], axis=1)\n",
        "\n",
        "normalized_df = (df - df.mean()) / df.std()\n",
        "df = normalized_df\n",
        "\n",
        "#print(df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, decomposition\n",
        "pca_feature_number = 14\n",
        "pca = decomposition.PCA(n_components = pca_feature_number)\n",
        "pca.fit(df)\n",
        "new_df = pca.transform(df)\n",
        "\n",
        "for i in range(pca_feature_number):\n",
        "  df['f_' + str(i)] = new_df[:,i]\n",
        "\n",
        "df = df.filter(like='f_')\n",
        "#print(df.info())"
      ],
      "metadata": {
        "id": "5UACp1HaMDak"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mx9qNUCl3pT3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV #cross validation (k-fold)\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, decomposition\n",
        "\n",
        "y = _dftarget\n",
        "split_at = 98\n",
        "\n",
        "for a in range(20):\n",
        "  i=a+1\n",
        "  pca_feature_number = i\n",
        "  pca = decomposition.PCA(n_components = pca_feature_number)\n",
        "  pca.fit(df)\n",
        "  new_df = pca.transform(df.copy())\n",
        "\n",
        "  _df = df.copy()\n",
        "\n",
        "  for j in range(i):\n",
        "    _df['f_' + str(j)] = new_df[:,j]\n",
        "\n",
        "  _df = _df.filter(like='f_')\n",
        "\n",
        "\n",
        "  X = _df.values[: , :]\n",
        "  who = \"pca-\" + str(i)\n",
        "\n",
        "  X_train = X[:split_at]\n",
        "  X_test = X[split_at:]\n",
        "\n",
        "  y_train = y[:split_at]\n",
        "  y_test = y[split_at:]\n",
        "\n",
        "\n",
        "  lr = LogisticRegressionCV(cv=5, random_state=0, class_weight='balanced') #scoring per cambiare metrica\n",
        "  lr.fit(X_train, y_train)\n",
        "  acc_s = lr.score(X_train, y_train)*100\n",
        "  acc_s_test = lr.score(X_test, y_test)*100\n",
        "\n",
        "  print( who + \";\" + \"{:.1f}\".format(acc_s) + \";\" + \"{:.1f}\".format(acc_s_test) +\";\" + \"{:.1f}\".format(acc_s+acc_s_test) )\n"
      ],
      "metadata": {
        "id": "74ApVoV072U4",
        "outputId": "192b3419-0393-4087-9e6f-9f5c1c36d14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pca-1;40.8;42.9;83.7\n",
            "pca-2;54.1;38.1;92.2\n",
            "pca-3;56.1;38.1;94.2\n",
            "pca-4;59.2;50.0;109.2\n",
            "pca-5;61.2;45.2;106.5\n",
            "pca-6;58.2;45.2;103.4\n",
            "pca-7;59.2;42.9;102.0\n",
            "pca-8;56.1;40.5;96.6\n",
            "pca-9;60.2;40.5;100.7\n",
            "pca-10;63.3;42.9;106.1\n",
            "pca-11;61.2;42.9;104.1\n",
            "pca-12;63.3;42.9;106.1\n",
            "pca-13;64.3;42.9;107.1\n",
            "pca-14;73.5;54.8;128.2\n",
            "pca-15;75.5;54.8;130.3\n",
            "pca-16;68.4;42.9;111.2\n",
            "pca-17;76.5;57.1;133.7\n",
            "pca-18;66.3;42.9;109.2\n",
            "pca-19;66.3;42.9;109.2\n",
            "pca-20;66.3;42.9;109.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80vdfkeh3uQf",
        "outputId": "ba2bb917-4b19-4b7c-9c91-fa6613564a4f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9;63.3;42.9;106.1\n",
            "area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 9 - 12;62.2;45.2;107.5\n",
            "area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 9 - 13;67.3;42.9;110.2\n",
            "area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 10 - 13;75.5;57.1;132.7\n",
            "area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 9 - 12 - 13;75.5;59.5;135.0\n",
            "area 0 - 1 - 2 - 3 - 4 - 6 - 7 - 10 - 12 - 13;77.6;64.3;141.8\n",
            "area 0 - 1 - 2 - 4 - 5 - 6 - 7 - 8 - 10 - 13;77.6;66.7;144.2\n",
            "area 0 - 2 - 3 - 4 - 5 - 6 - 7 - 10 - 12 - 13;74.5;71.4;145.9\n",
            "area 0 - 2 - 3 - 4 - 6 - 7 - 9 - 10 - 12 - 13;77.6;71.4;149.0\n",
            "area 0 - 2 - 4 - 5 - 6 - 7 - 10 - 11 - 12 - 13;74.5;76.2;150.7\n"
          ]
        }
      ],
      "source": [
        "y = _dftarget\n",
        "split_at = 98\n",
        "plottare = False\n",
        "\n",
        "#max_f1_score = 0\n",
        "#max_f1_score_who = \"\"\n",
        "max_accuracy_score = 0\n",
        "max_accuracy_score_who = \"\"\n",
        "\n",
        "for i in range(pca_feature_number):\n",
        "  for j in range(pca_feature_number):\n",
        "    for a in range(pca_feature_number):\n",
        "      for b in range(pca_feature_number):\n",
        "        for c in range(pca_feature_number):\n",
        "          for d in range(pca_feature_number):\n",
        "            for e in range(pca_feature_number):\n",
        "              for f in range(pca_feature_number):\n",
        "                for g in range(pca_feature_number):\n",
        "                  for h in range(pca_feature_number):\n",
        "\n",
        "                    if i<j and j<a and a<b and b<c and c<d and d<e and e<f and f<g and g<h:\n",
        "                    #if i==4 and j==7 and a==14:\n",
        "\n",
        "                      X = df.values[:, [i,j,a,b,c,d,e,f,g,h]]\n",
        "                      who = \"area \" + str(i) + \" - \" + str(j) + \" - \" + str(a) + \" - \" + str(b) + \" - \" + str(c) + \" - \" + str(d) + \" - \" + str(e) + \" - \" + str(f) + \" - \" + str(g) + \" - \" + str(h)\n",
        "\n",
        "                      X_train = X[:split_at]\n",
        "                      X_test = X[split_at:]\n",
        "\n",
        "                      y_train = y[:split_at]\n",
        "                      y_test = y[split_at:]\n",
        "\n",
        "                      # addestramento\n",
        "                      #lr = LogisticRegression(C=100.0, random_state=0, class_weight='balanced') #parametro C Ã¨ l'inverso della regolarizzazione; pertanto, se riduco il valore C, incremento la regolarizzazione; e viceversa\n",
        "                      lr = LogisticRegressionCV(cv=5, random_state=0, class_weight='balanced') #scoring per cambiare metrica\n",
        "                      lr.fit(X_train, y_train)\n",
        "                      acc_s = lr.score(X_train, y_train)*100\n",
        "                      acc_s_test = lr.score(X_test, y_test)*100\n",
        "\n",
        "                      #if acc_s+acc_s_test > 150:\n",
        "                      #print( who + \";\" + \"{:.1f}\".format(acc_s) + \";\" + \"{:.1f}\".format(acc_s_test) +\";\" + \"{:.1f}\".format(acc_s+acc_s_test) )\n",
        "                      #print( conf_mat )\n",
        "\n",
        "                      if max_accuracy_score < acc_s+acc_s_test:\n",
        "                        max_accuracy_score = acc_s+acc_s_test\n",
        "                        max_accuracy_score_who = who\n",
        "                        print( who + \";\" + \"{:.1f}\".format(acc_s) + \";\" + \"{:.1f}\".format(acc_s_test) +\";\" + \"{:.1f}\".format(acc_s+acc_s_test) )\n",
        "\n",
        "\n",
        "\n",
        "#print( max_f1_score_who )\n",
        "print( \"---------------------> \" + max_accuracy_score_who + \" \" + str(max_accuracy_score) )\n",
        "#print( conf_mat )\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/francescopandolfo/TESI_LM32/blob/main/variazione_relativa%20-%20eventi.ipynb",
      "authorship_tag": "ABX9TyOx6nIHvh2Vx7/jldBF8iNt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}