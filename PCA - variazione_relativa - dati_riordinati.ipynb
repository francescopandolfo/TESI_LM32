{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4BVpr7woYWn",
        "outputId": "604017f7-065f-40ef-8fcf-f4d5847219e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y6N3RVtrq6jm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pathDrive = 'drive/MyDrive/UNICT/_TESI/dati/'\n",
        "\n",
        "df = pd.read_csv(pathDrive + 'dati_interpolati_diff_1d-2d_8gg - riordinati.csv', sep=';')\n",
        "\n",
        "df['edam_ecne_eplu_diff'] = df['edam_ecne_eplu_diff'].str.replace(',','.').astype(float)#\n",
        "df['edam_ecor_emcn_diff'] = df['edam_ecor_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_emsg_eplu_diff'] = df['edam_emsg_eplu_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_epdn_ecne_diff'] = df['edam_epdn_ecne_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_epdn_emcn_diff'] = df['edam_epdn_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['eint_ecpn_emgl_diff'] = df['eint_ecpn_emgl_diff'].str.replace(',','.').astype(float)#\n",
        "df['eint_esln_emgl_diff'] = df['eint_esln_emgl_diff'].str.replace(',','.').astype(float)\n",
        "df['eint_esln_espc_diff'] = df['eint_esln_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['emeg_ecpn_emgl_diff'] = df['emeg_ecpn_emgl_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_ecor_ecri_diff'] = df['emfn_ecor_ecri_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_ecor_emcn_diff'] = df['emfn_ecor_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_emcn_epdn_diff'] = df['emfn_emcn_epdn_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_ecne_ecpn_diff'] = df['epdn_ecne_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_eint_ecpn_diff'] = df['epdn_eint_ecpn_diff'].str.replace(',','.').astype(float)##\n",
        "df['epdn_eint_espc_diff'] = df['epdn_eint_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_emfn_espc_diff'] = df['epdn_emfn_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_ecne_ecpn_diff'] = df['eplu_ecne_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emeg_ecpn_diff'] = df['eplu_emeg_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emeg_emal_diff'] = df['eplu_emeg_emal_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emsg_emal_diff'] = df['eplu_emsg_emal_diff'].str.replace(',','.').astype(float)\n",
        "\n",
        "\n",
        "df_train = df[:126]\n",
        "'''\n",
        "df_val = df[126:170]\n",
        "df_test = df[170:]\n",
        "'''\n",
        "df_test = df[126:]\n",
        "\n",
        "y_train = df_train['evento'].astype(int).values\n",
        "#y_val = df_val['evento'].astype(int).values\n",
        "y_test = df_test['evento'].astype(int).values\n",
        "#_dftarget = df['evento'].astype(int).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mx9qNUCl3pT3"
      },
      "outputs": [],
      "source": [
        "def toDataFrame(df):\n",
        "  format = '%d/%m/%Y'\n",
        "  df['date'] = pd.to_datetime(df['day'], format=format)\n",
        "  df = df.set_index('date')\n",
        "  df = df.drop(columns=['day'])\n",
        "  df = df.drop(columns=['evento'])\n",
        "\n",
        "  for i in reversed(range(len(df.columns))):\n",
        "    if df.dtypes[df.columns[i]] == 'object':\n",
        "      df = df.drop(df.columns[i], axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "df = toDataFrame(df)\n",
        "df_train = toDataFrame(df_train)\n",
        "#df_val = toDataFrame(df_val)\n",
        "df_test = toDataFrame(df_test)\n",
        "\n",
        "############## normalizzo tutto il dataframe\n",
        "#normalized_df = (df - df.mean()) / df.std()\n",
        "\n",
        "############## normalizzo le tre parti del dataset in base alla varianza del training\n",
        "df_train_mean = df_train.mean()\n",
        "df_train_std = df_train.std()\n",
        "\n",
        "normalized_df_train = (df_train - df_train_mean) / df_train_std\n",
        "#normalized_df_val   = (df_val - df_train_mean) / df_train_std\n",
        "normalized_df_test  = (df_test - df_train_mean) / df_train_std"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, decomposition\n",
        "\n",
        "pca_feature_number = 20\n",
        "pca = decomposition.PCA(n_components = pca_feature_number)\n",
        "pca.fit(normalized_df_train) #le PCA si genera a partire dai soli dati del training\n",
        "\n",
        "def applicaPca(pca_model, normalized_df):\n",
        "  temp_df = normalized_df.copy()\n",
        "  new_df = pca_model.transform(temp_df)\n",
        "\n",
        "  for i in range(pca_model.n_components):\n",
        "    temp_df['f_' + str(i)] = new_df[:,i]\n",
        "\n",
        "  return temp_df.filter(like='f_')\n",
        "\n",
        "df_train_pca = applicaPca(pca, normalized_df_train)\n",
        "#df_val_pca = applicaPca(pca, normalized_df_val)\n",
        "df_test_pca = applicaPca(pca, normalized_df_test)\n",
        "\n",
        "#df_test_pca.info()\n",
        "#pca.explained_variance_ratio_.cumsum()"
      ],
      "metadata": {
        "id": "5-tssgTho8FB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#calcola lo score in base all'algoritmo scelto (Random Forest, Logistic RegressionCV, ..) di tutte le prime componenti principali\n",
        "for i in range(pca_feature_number):\n",
        "  #clf = LogisticRegressionCV(cv=5, random_state=0, class_weight='balanced') #scoring per cambiare metrica\n",
        "  clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
        "\n",
        "  clf.fit(df_train_pca.values[:,:i+1], y_train)\n",
        "\n",
        "  acc_train = clf.score(df_train_pca.values[:,:i+1],  y_train)*100\n",
        "  #acc_val   = clf.score(df_val_pca.values[:,:i+1],    y_val)*100\n",
        "  acc_test  = clf.score(df_test_pca.values[:,:i+1],   y_test)*100\n",
        "  print( str(i+1) + \";\" + \"{:.1f}\".format(acc_train) + \";\" + \"{:.1f}\".format(acc_test) )\n",
        "'''"
      ],
      "metadata": {
        "id": "klmuADD762PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80vdfkeh3uQf",
        "outputId": "2fc33a13-4c59-4002-8dbe-5423e072147e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29116; area 0 - 1 - 6 - 7 - 11 - 14 - 15 - 16 - 19;58.7;81.0\n",
            "29117; area 0 - 1 - 6 - 7 - 11 - 14 - 15 - 17 - 18;60.3;63.5\n",
            "29121; area 0 - 1 - 6 - 7 - 11 - 14 - 16 - 17 - 19;62.7;69.8\n",
            "29124; area 0 - 1 - 6 - 7 - 11 - 15 - 16 - 17 - 18;63.5;71.4\n",
            "29125; area 0 - 1 - 6 - 7 - 11 - 15 - 16 - 17 - 19;64.3;69.8\n",
            "29205; area 0 - 1 - 6 - 8 - 9 - 10 - 11 - 15 - 18;65.1;57.1\n",
            "29285; area 0 - 1 - 6 - 8 - 9 - 11 - 12 - 16 - 18;65.9;71.4\n",
            "29437; area 0 - 1 - 6 - 8 - 10 - 11 - 14 - 16 - 19;67.5;65.1\n",
            "29581; area 0 - 1 - 6 - 8 - 11 - 14 - 15 - 18 - 19;61.1;79.4\n",
            "31892; area 0 - 2 - 3 - 4 - 5 - 6 - 8 - 9 - 11;69.8;57.1\n",
            "31911; area 0 - 2 - 3 - 4 - 5 - 6 - 8 - 11 - 13;70.6;55.6\n",
            "32478; area 0 - 2 - 3 - 4 - 5 - 8 - 14 - 15 - 18;71.4;50.8\n",
            "34287; area 0 - 2 - 3 - 4 - 8 - 11 - 15 - 16 - 18;72.2;60.3\n",
            "35124; area 0 - 2 - 3 - 5 - 6 - 8 - 10 - 16 - 18;69.8;71.4\n",
            "35483; area 0 - 2 - 3 - 5 - 6 - 12 - 13 - 16 - 18;70.6;71.4\n",
            "35550; area 0 - 2 - 3 - 5 - 7 - 8 - 9 - 10 - 18;73.0;54.0\n",
            "45253; area 0 - 2 - 5 - 6 - 7 - 11 - 15 - 16 - 17;69.0;76.2\n",
            "45473; area 0 - 2 - 5 - 6 - 8 - 10 - 11 - 15 - 18;73.8;63.5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "#y = _dftarget\n",
        "#split_at = 150\n",
        "\n",
        "#max_f1_score = 0\n",
        "#max_f1_score_who = \"\"\n",
        "max_accuracy_train = 0\n",
        "#max_accuracy_val = 0\n",
        "max_accuracy_tot = 0\n",
        "max_accuracy_test = 0\n",
        "\n",
        "max_accuracy_train_who = \"\"\n",
        "#max_accuracy_val_who = \"\"\n",
        "max_accuracy_tot_who = \"\"\n",
        "max_accuracy_test_who = \"\"\n",
        "\n",
        "stato_iniziale = True\n",
        "stato_iniziale_sequenza = [6,7,9,11,12,16,17,18,19]\n",
        "\n",
        "def get_range(indice):\n",
        "  if stato_iniziale:\n",
        "    return range(stato_iniziale_sequenza[indice], pca_feature_number)\n",
        "  else:\n",
        "    return range(pca_feature_number)\n",
        "\n",
        "\n",
        "#pca_feature_number = 20 #SOLO SE NON SI USA LA PCA\n",
        "\n",
        "for i in get_range(0):\n",
        "  for j in get_range(1):\n",
        "    for a in get_range(2):\n",
        "      for b in get_range(3):\n",
        "        for c in get_range(4):\n",
        "          for d in get_range(5):\n",
        "            for e in get_range(6):\n",
        "              for f in get_range(7):\n",
        "                for g in get_range(8):\n",
        "\n",
        "                  stato_iniziale = False\n",
        "                  if i<j and j<a and a<b and b<c and c<d and d<e and e<f and f<g:\n",
        "\n",
        "                    who = \"area \" + str(i) + \" - \" + str(j) + \" - \" + str(a) + \" - \" + str(b) + \" - \" + str(c) + \" - \" + str(d) + \" - \" + str(e) + \" - \" + str(f) + \" - \" + str(g)\n",
        "\n",
        "                    X_train = df_train_pca.values[:, [i,j,a,b,c,d,e,f,g]]\n",
        "                    #X_val   = df_val_pca.values[:, [i,j,a,b,c,d,e,f]]\n",
        "                    X_test  = df_test_pca.values[:, [i,j,a,b,c,d,e,f,g]]\n",
        "\n",
        "                    #X_train = X[:split_at]\n",
        "                    ##X_test = X[split_at:]\n",
        "\n",
        "                    #y_train = y[:split_at]\n",
        "                    #y_test = y[split_at:]\n",
        "\n",
        "                    ################ LOGISTIC REGRESSION with CROSS VALIDATION\n",
        "                    clf = LogisticRegressionCV(cv=5, random_state=0, class_weight='balanced') #scoring per cambiare metrica\n",
        "                    ################ RANDOM FOREST\n",
        "                    #clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "\n",
        "                    clf.fit(X_train, y_train)\n",
        "                    acc_train = clf.score(X_train,  y_train,  sample_weight=None)*100\n",
        "                    #acc_val   = clf.score(X_val,    y_val,    sample_weight=None)*100\n",
        "                    acc_test  = clf.score(X_test,   y_test,    sample_weight=None)*100\n",
        "                    #acc_s = np.mean(cross_val_score(clf, X_train, y_train, cv=5))*100\n",
        "\n",
        "                    acc_tot = acc_train + acc_test\n",
        "\n",
        "                    if (max_accuracy_train < acc_train or max_accuracy_test < acc_test or max_accuracy_tot < acc_tot) or (acc_test > 80) :\n",
        "                      print( who + \";\" + \"{:.1f}\".format(acc_train) + \";\" + \"{:.1f}\".format(acc_test) )\n",
        "\n",
        "                      if max_accuracy_train < acc_train:\n",
        "                        max_accuracy_train = acc_train\n",
        "                        max_accuracy_train_who = who\n",
        "\n",
        "                      if max_accuracy_test < acc_test:\n",
        "                        max_accuracy_test = acc_test\n",
        "                        max_accuracy_test_who = who\n",
        "\n",
        "                      if max_accuracy_tot < acc_tot:\n",
        "                        max_accuracy_tot = acc_tot\n",
        "\n",
        "\n",
        "#print( max_f1_score_who )\n",
        "#print( max_accuracy_score_who )\n",
        "print( \"---------------------> \" + max_accuracy_train_who + \" \" + str(max_accuracy_train) )\n",
        "print( \"---------------------> \" + max_accuracy_test_who + \" \" + str(max_accuracy_test) )\n",
        "#print( conf_mat )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}