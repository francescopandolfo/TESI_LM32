{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4BVpr7woYWn",
        "outputId": "723561e9-da81-49e2-ae0a-5af7c3fa0e52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y6N3RVtrq6jm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pathDrive = 'drive/MyDrive/UNICT/_TESI/dati/'\n",
        "\n",
        "df = pd.read_csv(pathDrive + 'dati_interpolati_diff_1d-2d_8gg - riordinati.csv', sep=';')\n",
        "\n",
        "df['edam_ecne_eplu_diff'] = df['edam_ecne_eplu_diff'].str.replace(',','.').astype(float)#\n",
        "df['edam_ecor_emcn_diff'] = df['edam_ecor_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_emsg_eplu_diff'] = df['edam_emsg_eplu_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_epdn_ecne_diff'] = df['edam_epdn_ecne_diff'].str.replace(',','.').astype(float)\n",
        "df['edam_epdn_emcn_diff'] = df['edam_epdn_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['eint_ecpn_emgl_diff'] = df['eint_ecpn_emgl_diff'].str.replace(',','.').astype(float)#\n",
        "df['eint_esln_emgl_diff'] = df['eint_esln_emgl_diff'].str.replace(',','.').astype(float)\n",
        "df['eint_esln_espc_diff'] = df['eint_esln_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['emeg_ecpn_emgl_diff'] = df['emeg_ecpn_emgl_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_ecor_ecri_diff'] = df['emfn_ecor_ecri_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_ecor_emcn_diff'] = df['emfn_ecor_emcn_diff'].str.replace(',','.').astype(float)\n",
        "df['emfn_emcn_epdn_diff'] = df['emfn_emcn_epdn_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_ecne_ecpn_diff'] = df['epdn_ecne_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_eint_ecpn_diff'] = df['epdn_eint_ecpn_diff'].str.replace(',','.').astype(float)##\n",
        "df['epdn_eint_espc_diff'] = df['epdn_eint_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['epdn_emfn_espc_diff'] = df['epdn_emfn_espc_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_ecne_ecpn_diff'] = df['eplu_ecne_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emeg_ecpn_diff'] = df['eplu_emeg_ecpn_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emeg_emal_diff'] = df['eplu_emeg_emal_diff'].str.replace(',','.').astype(float)\n",
        "df['eplu_emsg_emal_diff'] = df['eplu_emsg_emal_diff'].str.replace(',','.').astype(float)\n",
        "\n",
        "\n",
        "df_train = df[:126]\n",
        "df_val = df[126:170]\n",
        "df_test = df[170:]\n",
        "\n",
        "y_train = df_train['evento'].astype(int).values\n",
        "y_val = df_val['evento'].astype(int).values\n",
        "y_test = df_test['evento'].astype(int).values\n",
        "#_dftarget = df['evento'].astype(int).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mx9qNUCl3pT3"
      },
      "outputs": [],
      "source": [
        "def toDataFrame(df):\n",
        "  format = '%d/%m/%Y'\n",
        "  df['date'] = pd.to_datetime(df['day'], format=format)\n",
        "  df = df.set_index('date')\n",
        "  df = df.drop(columns=['day'])\n",
        "  df = df.drop(columns=['evento'])\n",
        "\n",
        "  for i in reversed(range(len(df.columns))):\n",
        "    if df.dtypes[df.columns[i]] == 'object':\n",
        "      df = df.drop(df.columns[i], axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "df = toDataFrame(df)\n",
        "df_train = toDataFrame(df_train)\n",
        "df_val = toDataFrame(df_val)\n",
        "df_test = toDataFrame(df_test)\n",
        "\n",
        "############## normalizzo tutto il dataframe\n",
        "#normalized_df = (df - df.mean()) / df.std()\n",
        "\n",
        "############## normalizzo le tre parti del dataset in base alla varianza del training\n",
        "df_train_mean = df_train.mean()\n",
        "df_train_std = df_train.std()\n",
        "\n",
        "normalized_df_train = (df_train - df_train_mean) / df_train_std\n",
        "normalized_df_val   = (df_val - df_train_mean) / df_train_std\n",
        "normalized_df_test  = (df_test - df_train_mean) / df_train_std"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, decomposition\n",
        "\n",
        "pca_feature_number = 20\n",
        "pca = decomposition.PCA(n_components = pca_feature_number)\n",
        "pca.fit(normalized_df_train) #le PCA si genera a partire dai soli dati del training\n",
        "\n",
        "def applicaPca(pca_model, normalized_df):\n",
        "  temp_df = normalized_df.copy()\n",
        "  new_df = pca_model.transform(temp_df)\n",
        "\n",
        "  for i in range(pca_model.n_components):\n",
        "    temp_df['f_' + str(i)] = new_df[:,i]\n",
        "\n",
        "  return temp_df.filter(like='f_')\n",
        "\n",
        "df_train_pca = applicaPca(pca, normalized_df_train)\n",
        "df_val_pca = applicaPca(pca, normalized_df_val)\n",
        "df_test_pca = applicaPca(pca, normalized_df_test)\n",
        "\n",
        "#df_test_pca.info()\n",
        "#pca.explained_variance_ratio_.cumsum()"
      ],
      "metadata": {
        "id": "5-tssgTho8FB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#calcola lo score in base all'algoritmo scelto (Random Forest, Logistic RegressionCV, ..) di tutte le prime componenti principali\n",
        "for i in range(pca_feature_number):\n",
        "  clf = LogisticRegressionCV(cv=5, random_state=0, class_weight='balanced') #scoring per cambiare metrica\n",
        "  #clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "\n",
        "  clf.fit(df_train_pca.values[:,:i+1], y_train)\n",
        "\n",
        "  acc_train = clf.score(df_train_pca.values[:,:i+1],  y_train)*100\n",
        "  acc_val   = clf.score(df_val_pca.values[:,:i+1],    y_val)*100\n",
        "  acc_test  = clf.score(df_test_pca.values[:,:i+1],   y_test)*100\n",
        "  print( str(i+1) + \";\" + \"{:.1f}\".format(acc_train) + \";\" + \"{:.1f}\".format(acc_val) +\";\" + \"{:.1f}\".format(acc_test) )\n",
        "'''"
      ],
      "metadata": {
        "id": "klmuADD762PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80vdfkeh3uQf",
        "outputId": "657d1c58-72a3-4020-b368-a9b1de8b0a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1; area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 7;92.9;72.7;68.4\n",
            "2; area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 8;92.9;75.0;68.4\n",
            "3; area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 9;93.7;65.9;68.4\n",
            "5; area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 11;95.2;75.0;73.7\n",
            "6; area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 12;92.9;79.5;68.4\n",
            "7; area 0 - 1 - 2 - 3 - 4 - 5 - 6 - 13;93.7;81.8;68.4\n",
            "17; area 0 - 1 - 2 - 3 - 4 - 5 - 7 - 11;97.6;68.2;68.4\n",
            "134; area 0 - 1 - 2 - 3 - 4 - 6 - 11 - 12;98.4;59.1;73.7\n",
            "170; area 0 - 1 - 2 - 3 - 4 - 7 - 8 - 9;99.2;52.3;68.4\n",
            "511; area 0 - 1 - 2 - 3 - 5 - 6 - 12 - 18;93.7;84.1;63.2\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "#y = _dftarget\n",
        "#split_at = 150\n",
        "\n",
        "#max_f1_score = 0\n",
        "#max_f1_score_who = \"\"\n",
        "max_accuracy_train = 0\n",
        "max_accuracy_val = 0\n",
        "max_accuracy_tot = 0\n",
        "max_accuracy_test = 0\n",
        "\n",
        "max_accuracy_train_who = \"\"\n",
        "max_accuracy_val_who = \"\"\n",
        "max_accuracy_tot_who = \"\"\n",
        "max_accuracy_test_who = \"\"\n",
        "contatore = 0\n",
        "\n",
        "#pca_feature_number = 20 #SOLO SE NON SI USA LA PCA\n",
        "\n",
        "for i in range(pca_feature_number):\n",
        "  for j in range(pca_feature_number):\n",
        "    for a in range(pca_feature_number):\n",
        "      for b in range(pca_feature_number):\n",
        "        for c in range(pca_feature_number):\n",
        "          for d in range(pca_feature_number):\n",
        "            for e in range(pca_feature_number):\n",
        "              for f in range(pca_feature_number):\n",
        "                #for g in range(pca_feature_number):\n",
        "\n",
        "                  #if i<j and j<a and a<b and b<c and c<d    and i==0 and j==1 and a==2 and b==3 and c==4 and d==5:\n",
        "                  if i<j and j<a and a<b and b<c and c<d and d<e and e<f:\n",
        "                    contatore += 1\n",
        "                    #if contatore > 49778:\n",
        "                    who = str(contatore) + \"; area \" + str(i) + \" - \" + str(j) + \" - \" + str(a) + \" - \" + str(b) + \" - \" + str(c) + \" - \" + str(d) + \" - \" + str(e) + \" - \" + str(f)\n",
        "\n",
        "                    X_train = df_train_pca.values[:, [i,j,a,b,c,d,e,f]]\n",
        "                    X_val   = df_val_pca.values[:, [i,j,a,b,c,d,e,f]]\n",
        "                    X_test  = df_test_pca.values[:, [i,j,a,b,c,d,e,f]]\n",
        "\n",
        "                    #X_train = X[:split_at]\n",
        "                    ##X_test = X[split_at:]\n",
        "\n",
        "                    #y_train = y[:split_at]\n",
        "                    #y_test = y[split_at:]\n",
        "\n",
        "                    ################ LOGISTIC REGRESSION with CROSS VALIDATION\n",
        "                    #clf = LogisticRegressionCV(cv=5, random_state=0, class_weight='balanced') #scoring per cambiare metrica\n",
        "                    ################ RANDOM FOREST\n",
        "                    clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
        "\n",
        "                    clf.fit(X_train, y_train)\n",
        "                    acc_train = clf.score(X_train,  y_train,  sample_weight=None)*100\n",
        "                    acc_val   = clf.score(X_val,    y_val,    sample_weight=None)*100\n",
        "                    acc_test  = clf.score(X_test,   y_test,    sample_weight=None)*100\n",
        "                    #acc_s = np.mean(cross_val_score(clf, X_train, y_train, cv=5))*100\n",
        "\n",
        "                    acc_tot = acc_train + acc_val\n",
        "\n",
        "                    if (max_accuracy_train < acc_train or max_accuracy_val < acc_val or max_accuracy_tot < acc_tot) or (acc_val >= 90) :\n",
        "                      print( who + \";\" + \"{:.1f}\".format(acc_train) + \";\" + \"{:.1f}\".format(acc_val) +\";\" + \"{:.1f}\".format(acc_test) )\n",
        "\n",
        "                      if max_accuracy_train < acc_train:\n",
        "                        max_accuracy_train = acc_train\n",
        "                        max_accuracy_train_who = who\n",
        "\n",
        "                      if max_accuracy_val < acc_val:\n",
        "                        max_accuracy_val = acc_val\n",
        "                        max_accuracy_val_who = who\n",
        "\n",
        "                      if max_accuracy_tot < acc_tot:\n",
        "                        max_accuracy_tot = acc_tot\n",
        "\n",
        "\n",
        "#print( max_f1_score_who )\n",
        "#print( max_accuracy_score_who )\n",
        "print( \"---------------------> \" + max_accuracy_train_who + \" \" + str(max_accuracy_train) )\n",
        "print( \"---------------------> \" + max_accuracy_val_who + \" \" + str(max_accuracy_val) )\n",
        "#print( conf_mat )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}